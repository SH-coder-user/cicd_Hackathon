# -*- coding: utf-8 -*-
"""ìŒì‹ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (LLM ë¹„í™œì„±í™” ì•ˆì „ê°€ë“œ ì ìš©)"""

from dotenv import load_dotenv
load_dotenv()

import base64
import os
import json
from typing import TypedDict

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (íŒ¨í‚¤ì§€ëŠ” ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langgraph.graph import StateGraph, END

# -----------------------------
# 0. ì´ˆê¸°í™” (LLM ë¹„í™œì„±í™” ê°€ë“œ)
# -----------------------------
USE_LLM = True  # ê¸°ë³¸ê°’: ì‚¬ìš©
try:
    # OPENAI_API_KEYê°€ ì—†ê±°ë‚˜ ì˜ëª»ë˜ë©´ ì—¬ê¸°ì„œ ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=os.getenv("OPENAI_API_KEY"))
except Exception as e:
    print("ğŸš¨ OpenAI ë˜ëŠ” LangChain ì´ˆê¸°í™” ì‹¤íŒ¨. LLM ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ê³  ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    print("ì›ì¸:", e)
    USE_LLM = False
    client = None
    llm = None

# -----------------------------
# ìƒíƒœ ì •ì˜
# -----------------------------
class State(TypedDict):
    analysis: str
    report: str
    improvements: str

# -----------------------------
# 1. ë©€í‹°ëª¨ë‹¬ ë¶„ì„ í•¨ìˆ˜
# -----------------------------
def analyze_food(image_path: str) -> str:
    """ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ ë¶„ì„ ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜."""
    # LLM ë¹„í™œì„± ì‹œ: ì‹¤ì œ ë¶„ì„ ëŒ€ì‹  ë”ë¯¸ ê²°ê³¼ ë°˜í™˜
    if not USE_LLM:
        dummy = {
            "food": "unknown",
            "leftover_ratio": "unknown",
            "note": "LLM disabled - returning dummy analysis"
        }
        return json.dumps(dummy, ensure_ascii=False)

    try:
        with open(image_path, "rb") as f:
            img_bytes = f.read()
        img_base64 = base64.b64encode(img_bytes).decode("utf-8")

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë‚¨ê¸´ ìŒì‹ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.",
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ìŒì‹ ì‚¬ì§„ì„ ë³´ê³  ìŒì‹ ì¢…ë¥˜ì™€ ë‚¨ì€ ì–‘ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.",
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"},
                        },
                    ],
                },
            ],
        )
        return response.choices[0].message.content
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {image_path}")
        return None
    except Exception as e:
        print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# -----------------------------
# 2. ë‹¨ì¼ ë…¸ë“œ: report + improve í†µí•©
# -----------------------------
if USE_LLM:
    combined_prompt = PromptTemplate(
        input_variables=["analysis"],
        template="""
ë¶„ì„ ê²°ê³¼: {analysis}

1) ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì”ë°˜ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
2) ë°˜ë“œì‹œ ê°œì„  ë°©ì•ˆì„ 1~3ê°œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3) ì ˆëŒ€ improvementsë¥¼ ë¹„ì›Œë‘ì§€ ë§ˆì„¸ìš”.
4) ì¶œë ¥ì€ **ìˆœìˆ˜ JSONë§Œ** ë°˜í™˜í•˜ì„¸ìš”. Markdown, ë¦¬ìŠ¤íŠ¸, ê¸€ë¨¸ë¦¬í‘œ ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ì¶œë ¥ ì˜ˆì‹œ(JSON í˜•ì‹):
{{
  "report": "ì˜¤ëŠ˜ ì œê³µëœ ìŒì‹ì˜ ì”ë°˜ì´ ...",
  "improvements": [
    {{"suggestion": "ìƒëŸ¬ë“œ ì–‘ ì¡°ì ˆ"}},
    {{"suggestion": "ë“œë ˆì‹± ì¢…ë¥˜ ë‹¤ì–‘í™”"}}
  ]
}}
"""
    )
    combined_chain = combined_prompt | llm
else:
    combined_prompt = None
    combined_chain = None

def combined_node(state: State):
    # LLM ë¹„í™œì„±: ê³ ì • ë¦¬í¬íŠ¸/ê°œì„ ì•ˆ ë°˜í™˜
    if not USE_LLM:
        try:
            parsed = json.loads(state.get("analysis") or "{}")
        except Exception:
            parsed = {}
        return {
            "report": "LLM ë¹„í™œì„± ìƒíƒœ: ë”ë¯¸ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤. ì‹¤ì œ ë¶„ì„ ëª¨ë¸ì„ í™œì„±í™”í•˜ë©´ ìƒì„¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤.",
            "improvements": [
                {"suggestion": "ëª¨ë¸ API í‚¤ ì„¤ì • í›„ ì¬ì‹¤í–‰"},
                {"suggestion": "ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ë‹¤ì–‘í™”í•˜ì—¬ í…ŒìŠ¤íŠ¸"},
            ],
        }

    # LLM í™œì„± ê²½ë¡œ
    result = combined_chain.invoke({"analysis": state["analysis"]})
    try:
        return json.loads(result.content)
    except json.JSONDecodeError:
        return {"report": result.content, "improvements": [{"suggestion": "LLM ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨"}]}

# -----------------------------
# 3. LangGraph êµ¬ì„±
# -----------------------------
def build_graph():
    """LLM ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ invoke()ë¥¼ ì œê³µí•˜ëŠ” ì‹¤í–‰ê¸°ë¥¼ ë°˜í™˜."""
    if not USE_LLM:
        # LangGraph ì—†ì´ë„ ë™ì¼ ì¸í„°í˜ì´ìŠ¤ë¥¼ í‰ë‚´ë‚´ëŠ” ë”ë¯¸ ì‹¤í–‰ê¸°
        class DummyApp:
            def invoke(self, init_state):
                # analyze ë…¸ë“œ ìŠ¤í‚µí•˜ê³  combined_nodeë§Œ ìˆ˜í–‰
                return combined_node(init_state)
        return DummyApp()

    # ì‹¤ì œ LangGraph ì‚¬ìš©
    graph = StateGraph(State)
    graph.add_node("analyze", lambda s: {"analysis": s["analysis"]})
    graph.add_node("combined", combined_node)
    graph.set_entry_point("analyze")
    graph.add_edge("analyze", "combined")
    graph.add_edge("combined", END)
    return graph.compile()

# -----------------------------
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------
def main():
    print("--- ìŒì‹ë¬¼ ì“°ë ˆê¸° ë¶„ì„ê¸° ---")
    image_path = input("ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ./data/Waffles50.jpg): ")

    if not os.path.exists(image_path):
        print(f"ì˜¤ë¥˜: '{image_path}' ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n1. ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
    analysis_result = analyze_food(image_path)

    if analysis_result:
        print("ë¶„ì„ ì™„ë£Œ!")
        app = build_graph()
        print("\n2. ë¦¬í¬íŠ¸ ë° ê°œì„  ë°©ì•ˆì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        final_output = app.invoke({"analysis": analysis_result})
        print("ìƒì„± ì™„ë£Œ!")

        print("\n--- ìµœì¢… ê²°ê³¼ ---")
        print("ğŸ“Œ ë¦¬í¬íŠ¸:")
        print(final_output.get("report", "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"))

        print("\nğŸ“Œ ê°œì„  ë°©ì•ˆ:")
        improvements = final_output.get("improvements", [])
        if isinstance(improvements, list):
            for item in improvements:
                print(f"- {item.get('suggestion', 'ê°œì„  ë°©ì•ˆ ì—†ìŒ')}")
        else:
            print(improvements)

if __name__ == "__main__":
    main()
